{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import datetime\n",
    "import requests\n",
    "import numpy as np\n",
    "import math\n",
    "import base64\n",
    "import from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "## 1 TicketMaster Face Value Data\n",
    "## 2 TicketMaster Resale Data\n",
    "## 3 SeatGeek Data\n",
    "## 4 StubHub Data\n",
    "## 5 Join DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 TicketMaster Data\n",
    "### List of cities and Ticketmaster codes\n",
    "City_List = \n",
    "    'Denver' : 264,\n",
    "    'San Francisco Bay': 382,\n",
    "    'Portland': 362,\n",
    "    'Los Angeles': 27,\n",
    "    'Las Vegas' : 14,\n",
    "    'Phoenix': 36, \n",
    "    'Seattle': 42,\n",
    "    'Austin' : 40, \n",
    "    'Houston': 22,\n",
    "    'Dallas' : 5,\n",
    "    'Chicago': 3,\n",
    "    'Nashville': 31,\n",
    "    'Atlanta': 10,\n",
    "    'Boston' : 11,\n",
    "    'New York': 35,\n",
    "    'Washington DC': 47,\n",
    "    'Miami' : 15\n",
    "### Ticketmaster API info    \n",
    "base_url = 'https://app.ticketmaster.com/discovery/v2/events.json?countryCode=US&apikey={apikey}'\n",
    "api_key = 'OhKdHqBZOOuGCrWIcjlhzoxmnjUoaGWL'\n",
    "dmaId = [382,362,264]\n",
    "marketId =  [42,27,14,36,40,22,5,3,31,10,11,35,47,15]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Define Functions\n",
    "\n",
    "Define functions for pulling event data from Ticketmaster API and formatting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#DMA and Market numbers\n",
    "dma_list = [382,362,264]\n",
    "mkt_list =  [42,27,14,36,40,22,5,3,31,10,11,35,47,15]\n",
    "\n",
    "# Function to get the number of pages of ticketmaster data\n",
    "def get_number_of_TM_pages(dma=None,market=None,source='ticketmaster,frontgate'):\n",
    "    url = 'https://app.ticketmaster.com/discovery/v2/events.json?countryCode=US'\n",
    "    payload = {'dmaId': dma, \n",
    "               'marketId': market, \n",
    "               'source': source,\n",
    "               'classificationName': 'music',\n",
    "               'size': '200',\n",
    "               'apikey':'OhKdHqBZOOuGCrWIcjlhzoxmnjUoaGWL'}\n",
    "    r = requests.get(url,params=payload,verify=True)\n",
    "    json_obj = json.loads(r.text)\n",
    "    return json_obj['page']['totalPages']\n",
    "\n",
    "#Get TicketMaster data, return a dataframe\n",
    "def getTicketMasterData(dma=None,market=None,page=None, source='ticketmaster,frontgate'):\n",
    "    url = 'https://app.ticketmaster.com/discovery/v2/events.json?countryCode=US'\n",
    "    payload = {'dmaId': dma, \n",
    "               'marketId': market, \n",
    "               'source': source,\n",
    "               'classificationName' : 'music',\n",
    "               'sort': 'date,name,asc',\n",
    "               'size': '200',\n",
    "               'page': page,\n",
    "               'apikey':'OhKdHqBZOOuGCrWIcjlhzoxmnjUoaGWL'}\n",
    "    r = requests.get(url,params=payload,verify=True)\n",
    "    json_response = json.loads(r.text)\n",
    "    event_info = []\n",
    "    for event in json_response.get('_embedded',{}).get('events',{}):\n",
    "         event_info.append({\n",
    "            'TM_id': event.get('id',{}),\n",
    "            'TM_name' : event.get('name',{}),\n",
    "            'TM_artist': list(attraction.get('name') for attraction in event['_embedded'].get('attractions',{})),\n",
    "            'TM_venue' : list(venue.get('name') for venue in event['_embedded'].get('venues',{}))[0],\n",
    "            'TM_venue_city' : list(venue.get('city',{}).get('name') for venue in event['_embedded'].get('venues',{}))[0],\n",
    "            'TM_venue_state' : list(venue.get('state',{}).get('stateCode') for venue in event['_embedded'].get('venues',{}))[0],\n",
    "            'TM_description' : event.get('description',{}),\n",
    "            'TM_more_info' : event.get('additionalInfo',{}),\n",
    "            'TM_start_date' : event.get('dates',{}).get('start',{}).get('dateTime',{}),\n",
    "            'TM_timezone' : event.get('dates',{}).get('timezone'),\n",
    "            'TM_span_multiple_days' : event.get('dates',{}).get('spanMultipleDays'),\n",
    "            'TM_presale_date_start' : list(presale.get('startDateTime',{}) for presale in event.get('sales').get('presales',{})),\n",
    "            'TM_presale_date_end' : list(presale.get('endDateTime',{}) for presale in event.get('sales').get('presales',{})),\n",
    "            'TM_sale_date_start' : event.get('sales',{}).get('public',{}).get('startDateTime'),\n",
    "            'TM_FV_prices': event.get('priceRanges'),\n",
    "            'TM_promoter': event.get('promoter',{}).get('name'),\n",
    "            'TM_genre' : event.get('classifications'),\n",
    "            'TM_place' : event.get('place')\n",
    "         })\n",
    "    tmDF = pd.DataFrame(event_info)\n",
    "    return tmDF\n",
    "\n",
    "#Convert timedate information from UTC to local time\n",
    "def convert_times(df,times_list,tz_col):\n",
    "    #Loop through each timezone\n",
    "    df_list = []\n",
    "    for tz in df[tz_col].unique():\n",
    "        #Filter rows by timezone\n",
    "        mask = (df[tz_col] == tz)\n",
    "        df_local = df.loc[mask]\n",
    "        #Loop through each datetime row\n",
    "        for col in times_list:\n",
    "            #Convert each column to datetime series, localize to UTC and then convert to proper timezone\n",
    "            df_local[col] = pd.to_datetime(df_local[col],errors='coerce').dt.tz_localize('UTC').dt.tz_convert(tz)\n",
    "            #Convert each column to datetime series, localize to UTC and then convert to proper timezone\n",
    "        df_list.append(df_local)\n",
    "    df = pd.concat(df_list, axis=0)\n",
    "    return df\n",
    "\n",
    "#Explode out columns with nested information\n",
    "def explode(df,col,index_col):\n",
    "    df1 = df[col].apply(pd.Series)\n",
    "    df1 = df1[0].apply(pd.Series)\n",
    "    df1.index = df[index_col]\n",
    "    df = df.merge(df1, how='left', left_on=index_col, right_index=True)\n",
    "    df = df.drop(col,axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Query Ticketmaster face value data\n",
    "### Pull the data and create the data frame\n",
    "For each city/market, get the number of pages of data, pull all data, and then concatanate the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv_df_list = []\n",
    "\n",
    "#Create dictionaries of dma/mkt numbers, and number of pages of data\n",
    "dma_dict = dict()\n",
    "mkt_dict = dict()\n",
    "#Get number of pages for face value dma items\n",
    "for dma in dma_list:\n",
    "    dma_dict[dma] = get_number_of_TM_pages(dma=dma)\n",
    "    \n",
    "#Get DMA data\n",
    "for dma in dma_dict.keys():\n",
    "    for page in range(1,dma_dict[dma]+1):\n",
    "        fv_df_list.append(getTicketMasterData(dma=dma,page=page))\n",
    "    \n",
    "#Get number of pages for face value market items\n",
    "for mkt in mkt_list:\n",
    "    mkt_dict[mkt] = get_number_of_TM_pages(market=mkt)\n",
    "    \n",
    "#Get market data\n",
    "for mkt in mkt_dict.keys():\n",
    "    for page in range(1,mkt_dict[mkt]+1):\n",
    "        fv_df_list.append(getTicketMasterData(market=mkt,page=page))\n",
    "        \n",
    "#Combine all dataframes for full data on events and face_value prices\n",
    "fv_df = pd.concat(fv_df_list,axis=0)\n",
    "\n",
    "fv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Convert datetime columns to datetime objects in  proper timezones\n",
    "Currently the four columns with datetime information are a mess. Some are of type dict, some are nested in lists, and all are in the UTC timezone. We can look and see that in timedate columns with lists of dates, the timedates are identitical, so we can unnest datetimes by simply taking the first element of the list.\n",
    "\n",
    "The 3 things we need to accomplish:\n",
    "    1. Convert all datetime columns to dtype string, and unnest 'TM_presale_date_end' and 'TM_presale_date_start' columns\n",
    "    2. Convert all columns to datetime series localized to UTC (Done in the convert_times function)\n",
    "    3. Filter rows by timezone, and loop over each datetime column to convert objects to their proper timezone (Done in the convert_times function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert all datetime columns to dtype string, and unnest objects\n",
    "fv_df['TM_presale_date_end'] = fv_df['TM_presale_date_end'].str[0]\n",
    "fv_df['TM_presale_date_start'] = fv_df['TM_presale_date_start'].str[0]\n",
    "fv_df['TM_start_date'] = fv_df['TM_start_date'].astype(str)\n",
    "fv_df['TM_sale_date_start'] = fv_df['TM_sale_date_start'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. Convert all columns to datetime series localized to UTC\n",
    "# 3. Filter rows by timezone and create a new dataframe per timezone, loop over each datetime column to convert objects to their proper timezone \n",
    "col_list = ['TM_presale_date_end','TM_presale_date_start','TM_start_date','TM_sale_date_start']\n",
    "fv_df = convert_times(df=fv_df,times_list=col_list,tz_col='TM_timezone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Explode nested rows\n",
    "Unnest information in prices and genre column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Explode price column\n",
    "fv_df = explode(df=fv_df,col='TM_FV_prices',index_col='TM_id')\n",
    "fv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv_df'TM_genre'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Unnest genre info and clean up data in exploded columns\n",
    "#fv_df = explode(fv_df,'TM_genre','TM_id')\n",
    "# for col in ['genre','subType']:\n",
    "#     fv_df[col] = fv_df[col].map(lambda x: x.get('name',{}))\n",
    "# fv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Query TicketMaster resale data and merge with face value data\n",
    "Next we will query TicketMaster's resale ticket data and then merge it with the face value dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query resale data from the Ticketmaster API\n",
    "\n",
    "rv_df_list = []\n",
    "\n",
    "#Create dictionaries of dma/mkt numbers, and number of pages of data\n",
    "dma_rv_dict = dict()\n",
    "mkt_rv_dict = dict()\n",
    "#Get number of pages for resale value dma items\n",
    "for dma in dma_list:\n",
    "    dma_rv_dict[dma] = get_number_of_TM_pages(dma=dma,source='tmr')\n",
    "    \n",
    "#Get DMA data\n",
    "for dma in dma_rv_dict.keys():\n",
    "    for page in range(1,dma_dict[dma]+1):\n",
    "        fv_df_list.append(getTicketMasterData(dma=dma,page=page,source='tmr'))\n",
    "    \n",
    "#Get number of pages for resale value market items\n",
    "for mkt in mkt_list:\n",
    "    mkt_rv_dict[mkt] = get_number_of_TM_pages(market=mkt,source='tmr')\n",
    "    \n",
    "#Get market data\n",
    "for mkt in mkt_rv_dict.keys():\n",
    "    for page in range(1,mkt_dict[mkt]+1):\n",
    "        fv_df_list.append(getTicketMasterData(market=mkt,page=page,source='tmr'))\n",
    "        \n",
    "#Combine all dataframes for full data on events and resale value prices\n",
    "rv_df = pd.concat(fv_df_list,axis=0)\n",
    "rv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Extract price information and merge it with face value data in a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode out resale price information\n",
    "rv_df = explode(rv_df,'TM_FV_prices','TM_id')\n",
    "rv_df.rename(columns={'min': 'tmr_min', 'max': 'tmr_max'}, inplace=True)\n",
    "# Create a new dataframe combining face value and resale value information, joined on ticketmaster event ID\n",
    "joined_df = fv_df.join(rv_df[['tmr_min','tmr_max']],on='TM_id',how='outer')\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Download Resale Data from SeatGeek API\n",
    "1. Connect to SeatGeek API and download data\n",
    "2. Merge data with TicketMaster DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to SeatGeek API and determine number of pages of information\n",
    "def get_SeatGeek_Pages():\n",
    "    url = 'https://api.seatgeek.com/2/events?format=json'\n",
    "    payload = {'per_page' : 1000,\n",
    "               'taxonomies.name':'concert',\n",
    "               'client_id': 'OTU5MDE5MXwxNTEwMzcxNjgyLjIx',\n",
    "              }\n",
    "    r = requests.get(url, params=payload,verify=True)\n",
    "    json_obj = json.loads(r.text)\n",
    "    #Return the total number of JSON items divided by the number of page to get page count\n",
    "    return math.ceil(json_obj['meta']['total']/json_obj['meta']['per_page'])\n",
    "\n",
    "#Connect to SeatGeek API and download JSON data, format it into pandas dataframe\n",
    "def get_SeatGeek_data(page=1):\n",
    "    url = 'https://api.seatgeek.com/2/events?format=json'\n",
    "    payload = {'per_page' : 1000,\n",
    "               'page' : page,\n",
    "               'taxonomies.name':'concert',\n",
    "               'client_id': 'OTU5MDE5MXwxNTEwMzcxNjgyLjIx',\n",
    "              }\n",
    "    r = requests.get(url,params=payload,verify=True)\n",
    "    json_obj = json.loads(r.text)\n",
    "    info_list = []\n",
    "    for event in json_obj['events']:\n",
    "        info_list.append(\n",
    "         {'SG_listing_count' : event.get('stats',{}).get('listing_count',{}),\n",
    "         'SG_average_price' : event.get('stats',{}).get('average_price',{}),\n",
    "         'SG_lowest_price' : event.get('stats',{}).get('lowest_price',{}),\n",
    "         'SG_highest_price' : event.get('stats',{}).get('highest_price',{}),\n",
    "         'SG_title' : event.get('title',{}),\n",
    "         'SG_datetime_local' : event.get('datetime_local',{}),\n",
    "         'SG_artists' : [performer.get('name',{}) for performer in event.get('performers',{})],\n",
    "         'SG_artists_score' : [performer.get('score',{}) for performer in event.get('performers',{})],\n",
    "         'SG_artists_type' : [performer.get('type',{}) for performer in event.get('performers',{})],\n",
    "         'SG_venue' : event.get('venue',{}).get('name',{}),\n",
    "         'SG_venue_city' : event.get('venue',{}).get('city',{}),\n",
    "         'SG_venue_state' : event.get('venue',{}).get('state',{}),\n",
    "         'SG_venue_score' : event.get('venue',{}).get('score',{})})\n",
    "    sgdf = pd.DataFrame(info_list)\n",
    "    return sgdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Download SeatGeek data into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgdf_list = []\n",
    "#Find the total number of pages in \n",
    "total_pages = get_SeatGeek_Pages()\n",
    "#Loop through the number pages of data and combine data into single dataframe\n",
    "for pageNum in range(1,total_pages+1):\n",
    "    sgdf_list.append(get_SeatGeek_data(page=pageNum))\n",
    "sgdf = pd.concat(sgdf_list,axis=0)\n",
    "sgdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 StubHub Data\n",
    "Connect to StubHub API and download data\n",
    "\n",
    "### 4.1 Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = '57476f0a-f69e-334d-ba1b-02d394883b2a'\n",
    "user_GUID = '84175DB4D85A6777E04400144FB7AE36'\n",
    "\n",
    "#Get number of pages of data\n",
    "def get_SH_pages():\n",
    "    url = 'https://api.stubhub.com/search/catalog/events/v3/'\n",
    "    payload = {'minAvailableTickets':1, \n",
    "              'categoryName':'Concert',\n",
    "              'country' : 'US'}\n",
    "    headers = {'Authorization': 'Bearer ' + access_token} # Insert StubHub API Key here\n",
    "    r = requests.get(url, params=payload, headers=headers, verify=True)\n",
    "    json_response = json.loads(r.text)\n",
    "    return math.ceil(json_response.get('numFound',{})/500)\n",
    "\n",
    "#Connect to StubHub API and put data into DataFrame\n",
    "def get_SH_data(start):\n",
    "    url = 'https://api.stubhub.com/search/catalog/events/v3/'\n",
    "    payload = {'minAvailableTickets':1, \n",
    "              'categoryName':'Concert',\n",
    "               'rows' : 500,\n",
    "               'start' : start,\n",
    "               'country' : 'US'}\n",
    "    headers = {'Authorization': 'Bearer ' + access_token} # Insert StubHub API Key here\n",
    "    r = requests.get(url, params=payload, headers=headers, verify=True)\n",
    "    json_response = json.loads(r.text)\n",
    "    event_info = []\n",
    "    for event in json_response.get('events',{}):\n",
    "            event_info.append({\n",
    "                    'SH_artist':event.get('ancestors',{}).get('performers',{}),\n",
    "                    'SH_date':str(event.get('eventDateLocal',{})),\n",
    "                    'SH_event_id':str(event.get('id',{})),\n",
    "                    'SH_min_price':str(event.get('ticketInfo',{}).get('minPrice',{})),\n",
    "                    'SH_max_price':str(event.get('ticketInfo',{}).get('maxPrice')),\n",
    "                    'SH_total_postings':str(event.get('ticketInfo',{}).get('totalPostings')),\n",
    "                    'SH_total_tickets':str(event.get('ticketInfo',{}).get('totalTickets')),\n",
    "                    'SH_venue':str(event['venue'].get('name')),\n",
    "                    'SH_city':str(event['venue'].get('city')),\n",
    "                    'SH_state':str(event['venue'].get('state'))\n",
    "                })\n",
    "    TicketData = pd.DataFrame(event_info)\n",
    "    return TicketData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Gather data and concat into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SH_artist</th>\n",
       "      <th>SH_city</th>\n",
       "      <th>SH_date</th>\n",
       "      <th>SH_event_id</th>\n",
       "      <th>SH_max_price</th>\n",
       "      <th>SH_min_price</th>\n",
       "      <th>SH_state</th>\n",
       "      <th>SH_total_postings</th>\n",
       "      <th>SH_total_tickets</th>\n",
       "      <th>SH_venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'id': 5984, 'name': 'Bruce Springsteen', 'ur...</td>\n",
       "      <td>New York</td>\n",
       "      <td>2017-12-29T20:00:00-0500</td>\n",
       "      <td>103170465</td>\n",
       "      <td>6668.5</td>\n",
       "      <td>2030.5</td>\n",
       "      <td>NY</td>\n",
       "      <td>32</td>\n",
       "      <td>59</td>\n",
       "      <td>Walter Kerr Theatre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'id': 5984, 'name': 'Bruce Springsteen', 'ur...</td>\n",
       "      <td>New York</td>\n",
       "      <td>2018-01-09T20:00:00-0500</td>\n",
       "      <td>103170471</td>\n",
       "      <td>9602.5</td>\n",
       "      <td>3002.5</td>\n",
       "      <td>NY</td>\n",
       "      <td>21</td>\n",
       "      <td>37</td>\n",
       "      <td>Walter Kerr Theatre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'id': 492049, 'name': 'Black Veil Brides', '...</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>2018-02-24T20:00:00-0800</td>\n",
       "      <td>103228116</td>\n",
       "      <td>1362.8</td>\n",
       "      <td>55.3</td>\n",
       "      <td>WA</td>\n",
       "      <td>16</td>\n",
       "      <td>62</td>\n",
       "      <td>Showbox Sodo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'id': 196736, 'name': 'Joe Bonamassa', 'url'...</td>\n",
       "      <td>Chattanooga</td>\n",
       "      <td>2017-12-04T20:00:00-0500</td>\n",
       "      <td>9864305</td>\n",
       "      <td>919.3</td>\n",
       "      <td>121.3</td>\n",
       "      <td>TN</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>Soldiers and Sailors Memorial Auditorium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'id': 712224, 'name': 'Walk Off The Earth', ...</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>2018-03-03T19:00:00-0800</td>\n",
       "      <td>103271420</td>\n",
       "      <td>91.3</td>\n",
       "      <td>60.08</td>\n",
       "      <td>NV</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>House of Blues Las Vegas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           SH_artist      SH_city  \\\n",
       "0  [{'id': 5984, 'name': 'Bruce Springsteen', 'ur...     New York   \n",
       "1  [{'id': 5984, 'name': 'Bruce Springsteen', 'ur...     New York   \n",
       "2  [{'id': 492049, 'name': 'Black Veil Brides', '...      Seattle   \n",
       "3  [{'id': 196736, 'name': 'Joe Bonamassa', 'url'...  Chattanooga   \n",
       "4  [{'id': 712224, 'name': 'Walk Off The Earth', ...    Las Vegas   \n",
       "\n",
       "                    SH_date SH_event_id SH_max_price SH_min_price SH_state  \\\n",
       "0  2017-12-29T20:00:00-0500   103170465       6668.5       2030.5       NY   \n",
       "1  2018-01-09T20:00:00-0500   103170471       9602.5       3002.5       NY   \n",
       "2  2018-02-24T20:00:00-0800   103228116       1362.8         55.3       WA   \n",
       "3  2017-12-04T20:00:00-0500     9864305        919.3        121.3       TN   \n",
       "4  2018-03-03T19:00:00-0800   103271420         91.3        60.08       NV   \n",
       "\n",
       "  SH_total_postings SH_total_tickets                                  SH_venue  \n",
       "0                32               59                       Walter Kerr Theatre  \n",
       "1                21               37                       Walter Kerr Theatre  \n",
       "2                16               62                              Showbox Sodo  \n",
       "3                15               46  Soldiers and Sailors Memorial Auditorium  \n",
       "4                 6               41                  House of Blues Las Vegas  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages = get_SH_pages()\n",
    "SH_df_list = []\n",
    "for page in range(pages):\n",
    "     start_place = page * 500\n",
    "     SH_df_list.append(get_SH_data(start=start_place))\n",
    "SH_df = pd.concat(SH_df_list,axis=0)\n",
    "\n",
    "SH_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Convert to datetimes, Explode out artist names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#From string to datetime\n",
    "SH_df['SH_date'] = pd.to_datetime(SH_df['SH_date'])\n",
    "\n",
    "#Explode out artists column\n",
    "SH_df = explode(SH_df,'SH_artist','SH_event_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Join dataframes on venue name fuzzy match and datetime\n",
    "### 5.1 Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to find fuzzy matches from one DF to another\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
