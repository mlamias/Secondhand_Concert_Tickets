{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of Contents\n",
    "    1. Data Preprocessing\n",
    "    2. Linear Regression\n",
    "        1. Standard Linear Regression\n",
    "        2. ElasticNet\n",
    "        3. Lasso\n",
    "        4. Comparison of Methods\n",
    "    3. Classification\n",
    "        1. Setup\n",
    "        2. Classifier Evaluation (With 3 bins and 4 bins)\n",
    "        3. Learning Curves\n",
    "        4. Feature Importance Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['artists', 'date', 'TM_id', 'event_title', 'presale_date_end',\n",
       "       'presale_date_start', 'promoter', 'TM_sale_date_start',\n",
       "       'span multiple days', 'venue', 'TM_venue _lat', 'venue_city',\n",
       "       'TM_venue_long', 'venue_state', 'TM_max', 'TM_min', 'genre', 'subGenre',\n",
       "       'event_type', 'SG_artists_score', 'SG_average_price',\n",
       "       'SG_listing_count', 'SG_max_price', 'SG_min_price', 'SG_venue_score',\n",
       "       'SH_max_price', 'SH_min_price', 'SH_total_postings', 'SH_total_tickets',\n",
       "       'spotify_followers', 'spotify_popularity', 'spotify_avg_followers',\n",
       "       'spotify_avg_popularity', 'spotify_null_count', 'days_until_show',\n",
       "       'day_of_week', 'presale_length', 'days_on_sale', 'artist_count',\n",
       "       'avg_resale_min', 'avg_resale_max', 'min_source', 'max_source',\n",
       "       'min_markup%', 'max_markup%', 'avg_ticket_listings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.set_style()\n",
    "path = 'Pickles/output_df.pkl'\n",
    "df = pd.read_pickle(path)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing\n",
    "Drop extra columns and one hot encode categorical features (Dropping the first category to avoid collinearity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Drop excess columns \n",
    "df = df[['min_markup%','promoter','venue_state','TM_min','genre','subGenre','spotify_avg_followers',\n",
    "         'spotify_avg_popularity','spotify_null_count','days_until_show','day_of_week',\n",
    "         'presale_length','days_on_sale','artist_count','min_source','avg_ticket_listings']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot Encode categorical variables\n",
    "df_onehot = pd.get_dummies(columns=['promoter','venue_state','genre','min_source','subGenre','day_of_week'],\n",
    "                           data=df,drop_first=True)\n",
    "\n",
    "#Seperate into X and Y matrices\n",
    "X = df_onehot.iloc[:,1:]\n",
    "Y = df_onehot['min_markup%']\n",
    "\n",
    "#Split into training and test set\n",
    "X,X_test,Y,Y_test =  train_test_split(X,Y,test_size=.2,random_state=1)\n",
    "\n",
    "#Scale numerical data\n",
    "cont_features = ['TM_min','spotify_avg_followers',\n",
    "'spotify_avg_popularity','days_until_show','presale_length','days_on_sale',\n",
    " 'artist_count','avg_ticket_listings']\n",
    "Xscaler = StandardScaler()\n",
    "X[cont_features] = Xscaler.fit_transform(X[cont_features])\n",
    "X_test[cont_features] = Xscaler.transform(X_test[cont_features])\n",
    "\n",
    "#Create log scaled Y data for train and test data sets\n",
    "Y_log = Y.copy()\n",
    "Y_log[Y_log <= 0] = .01\n",
    "Y_log = np.log(Y_log)\n",
    "\n",
    "Y_testlog = Y_test.copy()\n",
    "Y_testlog[Y_testlog <= 0] = .01\n",
    "Y_testlog = np.log(Y_testlog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear Regression\n",
    "    1. Model Comparison\n",
    "    2. Residual Plots\n",
    "    \n",
    "### 2.1 Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make MSE and R squared CV scorers\n",
    "cv_mse = metrics.make_scorer(score_func=metrics.mean_squared_error)\n",
    "cv_r = metrics.make_scorer(score_func=metrics.r2_score)\n",
    "kfold = KFold(n_splits=5,shuffle=True,random_state=1)\n",
    "\n",
    "#Initialize regression objects\n",
    "lr = linear_model.LinearRegression()\n",
    "en = linear_model.ElasticNetCV(alphas=np.logspace(-6,.5,30,base=2),cv=kfold,max_iter=10000,random_state=1)\n",
    "lasso = linear_model.LassoCV(alphas=np.logspace(-6,.5,30,base=2),cv=kfold,max_iter=10000,random_state=1)\n",
    "abr = ensemble.AdaBoostRegressor(random_state=1)\n",
    "gbr = ensemble.GradientBoostingRegressor(random_state=1)\n",
    "rfr = ensemble.RandomForestRegressor(random_state=1)\n",
    "\n",
    "#Initialize regression objects to train with log transformed Y data\n",
    "lr_log = linear_model.LinearRegression()\n",
    "en_log = linear_model.ElasticNetCV(alphas=np.logspace(-6,.5,30,base=2),cv=kfold,max_iter=10000,random_state=1)\n",
    "lasso_log = linear_model.LassoCV(alphas=np.logspace(-6,.5,30,base=2),cv=kfold,max_iter=10000,random_state=1)\n",
    "abr_log = ensemble.AdaBoostRegressor(random_state=1)\n",
    "gbr_log = ensemble.GradientBoostingRegressor(random_state=1)\n",
    "rfr_log = ensemble.RandomForestRegressor(random_state=1)\n",
    "\n",
    "lin_models = {'Standard': lr,\n",
    "             'ElasticNet' : en,\n",
    "             'Lasso' : lasso,\n",
    "             'Ada Boosting' : abr,\n",
    "             'Gradient Boosting': gbr,\n",
    "             'Random Forest': rfr}\n",
    "lin_models_log = {'Standard Log': lr_log,\n",
    "             'ElasticNet Log' : lr_log,\n",
    "             'Lasso Log' : lasso_log,\n",
    "             'Ada Boosting Log' : abr_log,\n",
    "             'Gradient Boosting Log': gbr_log,\n",
    "             'Random Forest Log': rfr_log}\n",
    "\n",
    "def fit_lin_regression(model,name,Y=Y):\n",
    "    #Calculate R Values\n",
    "    r_values = cross_val_score(estimator=model,X=X,y=Y,cv=kfold,scoring=cv_r)\n",
    "    #Calculate MSE Values\n",
    "    mse_values = cross_val_score(estimator=model,X=X,y=Y,cv=kfold,scoring=cv_mse)\n",
    "    \n",
    "    model.fit(X,Y)\n",
    "    #Create dataframe of coefficients and weights\n",
    "    try:\n",
    "        coef_df = pd.DataFrame({'Feature': X.columns,'Coefficient': model.coef_})\n",
    "        # Find number of coefficients\n",
    "        coef_total = len(coef_df['Coefficient'].loc[coef_df['Coefficient'] != 0])\n",
    "    except AttributeError:\n",
    "        coef_df = np.nan\n",
    "        coef_total = np.nan\n",
    "    \n",
    "    #Append R^2 and MSE metrics to lists\n",
    "    avg_r2_train.append(r_values.mean())\n",
    "    std_r2_train.append(r_values.std())\n",
    "    avg_mse_train.append(mse_values.mean())\n",
    "    std_mse_train.append(mse_values.std())\n",
    "    coef_count.append(coef_total)\n",
    "    coef_weights[name] = coef_df\n",
    "\n",
    "def predict_lin_regression(model,name,Y_test=Y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse_test.append(metrics.mean_squared_error(Y_test,y_pred))\n",
    "    r2_test.append(metrics.r2_score(Y_test,y_pred))\n",
    "    \n",
    "def plot_residuals(model,name,X=X,Y=Y):\n",
    "    Y_fitted= model.predict(X=X)\n",
    "    residuals = np.subtract(Y_fitted,Y)\n",
    "    g = plt.scatter(Y_fitted,residuals,alpha=.4)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create lists of model metrics for train data\n",
    "avg_r2_train = []\n",
    "std_r2_train = []\n",
    "avg_mse_train = []\n",
    "std_mse_train = []\n",
    "coef_count = []\n",
    "coef_weights = dict()\n",
    "\n",
    "#Evaluate models\n",
    "for key in lin_models.keys():\n",
    "    fit_lin_regression(lin_models[key],key)\n",
    "    \n",
    "#Evaluate models (With Log Transformed Y)\n",
    "for key in lin_models_log.keys():\n",
    "    fit_lin_regression(lin_models_log[key],key,Y=Y_log)\n",
    "\n",
    "reg_models = [key for key in lin_models.keys()] + [key for key in lin_models_log.keys()]\n",
    "\n",
    "#Create dataframe of models and metrics\n",
    "results_df = pd.DataFrame({'Model' : reg_models,\n",
    "                           'R2 Mean' : avg_r2_train,\n",
    "                           'R2 Std' : std_r2_train,\n",
    "                           'MSE Mean' : avg_mse_train,\n",
    "                           'MSE Std' : std_mse_train,\n",
    "                           'Coefficients Count' : coef_count})\n",
    "\n",
    "results_df[['Model','R2 Mean','R2 Std','MSE Mean','MSE Std','Coefficients Count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create lists of metrics on test data\n",
    "r2_test = []\n",
    "mse_test = []\n",
    "\n",
    "#Evaluate models on the test data\n",
    "for key in lin_models.keys():\n",
    "    predict_lin_regression(lin_models[key],key)\n",
    "    \n",
    "#Evaluate models (With Log Transformed Y)\n",
    "for key in lin_models_log.keys():\n",
    "    predict_lin_regression(lin_models_log[key],key,Y_test=Y_testlog)\n",
    "\n",
    "#Create dataframe of models and metrics\n",
    "test_results_df = pd.DataFrame({'Model' : reg_models,\n",
    "                                'R2' : r2_test,\n",
    "                                'MSE' : mse_test})\n",
    "                 \n",
    "test_results_df[['Model','R2','MSE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis:\n",
    "MSE and $R^2$ values are similar on the train and test data, suggesting the models are not particularly overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Residual Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Residual plots\n",
    "\n",
    "subplt = 1\n",
    "f, ax = plt.subplots(2,3, sharex=True, sharey=True, figsize=[10,5])\n",
    "\n",
    "for key in lin_models.keys():\n",
    "    plt.subplot(2,3,subplt)\n",
    "    plt.title(key,size='medium')\n",
    "    trainplot = plot_residuals(lin_models[key],key,X=X)\n",
    "    testplot = plot_residuals(lin_models[key],key,X=X_test,Y=Y_test)\n",
    "    trainplot.set_color('b')\n",
    "    testplot.set_color('r')\n",
    "    testplot.set_alpha(.3)\n",
    "    subplt +=1\n",
    "f.text(0.6, 0, 'Fitted Y', ha='center',size='large')\n",
    "f.text(0, 0.5, 'Residuals', va='center', rotation='vertical',size='large')\n",
    "plt.tight_layout()\n",
    "plt.legend([trainplot,testplot],['Training Data','Test Data'],loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Residuals with Y log transformation\n",
    "subplt = 1\n",
    "f, ax = plt.subplots(2,3, sharex=True, sharey=True, figsize=[10,5])\n",
    "\n",
    "for key in lin_models_log.keys():\n",
    "    plt.subplot(2,3,subplt)\n",
    "    plt.title(key,size='medium')\n",
    "    trainplot = plot_residuals(lin_models_log[key],key,Y=Y_log)\n",
    "    trainplot.set_color('b')\n",
    "    testplot = plot_residuals(lin_models_log[key],key,X=X_test,Y=Y_testlog)\n",
    "    testplot.set_color('r')\n",
    "    testplot.set_alpha(.3)\n",
    "    subplt +=1\n",
    "f.text(0.6, 0, 'Fitted Y (Log)', ha='center',size='large')\n",
    "f.text(0, 0.5, 'Residuals', va='center', rotation='vertical',size='large')\n",
    "plt.legend([trainplot,testplot],['Training Data','Test Data'],loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "How to interpret MSE vs R squared?\n",
    "\n",
    "## 3. MultiClass Classification\n",
    "    1. Variable & Function Setup\n",
    "    2. Classifier Evaluation with 3 & 4 Bins\n",
    "    3. Learning Curves\n",
    "    4. Feature Importance Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup stratified KFold\n",
    "cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=1)\n",
    "\n",
    "#Initialize classifier objects\n",
    "lgr = linear_model.LogisticRegression(penalty=\"l1\",solver='saga',max_iter=10000,multi_class='multinomial')\n",
    "rfc = RandomForestClassifier(random_state=1)\n",
    "gbc = GradientBoostingClassifier(random_state=1)\n",
    "abc = AdaBoostClassifier(random_state=1)\n",
    "classifiers = [lgr,rfc,gbc,abc]\n",
    "algo_list = [\"Logistic Regression\",\"Random Forest\",\n",
    "             \"Gradient Boosting\",'Ada Boosting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_eval(classifiers,bins):\n",
    "   # Classify Y values into bins\n",
    "    Y_bins, bins = pd.qcut(Y,q=bins,retbins=True,labels=list(range(bins)))\n",
    "    \n",
    "    cv_results = []\n",
    "    cv_means = []\n",
    "    cv_std = []\n",
    "    \n",
    "    #Evaluate each classifier\n",
    "    for classifier in classifiers:\n",
    "        cv_results.append(cross_val_score(classifier, X, Y_bins, \n",
    "                                      scoring = 'accuracy',cv = cv))\n",
    "    #Split into result means and standard deviations\n",
    "    for cv_result in cv_results:\n",
    "        cv_means.append(cv_result.mean())\n",
    "        cv_std.append(cv_result.std())\n",
    "    \n",
    "    #Draw dataframe of results\n",
    "    cv_res = pd.DataFrame(\n",
    "        {\"CrossValMeans\":cv_means,\n",
    "         \"CrossValerrors\": cv_std,\n",
    "         \"Algorithm\":algo_list})\n",
    "    \n",
    "    g = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res,orient = \"h\",**{'xerr':cv_std})\n",
    "   \n",
    "    return Y_bins, bins, cv_res, g\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Evaluate with 3 bins\n",
    "Y_bins3, bins3_labels, cv_res3, g3 = classifier_eval(classifiers,bins=3)\n",
    "g3.set_title(\"Cross Validation Score (3 Bins)\")\n",
    "plt.axvline(np.divide(1,3), color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Markup Percentage Bins:\\n [{} - {}), \\n [{} - {}), \\n [{} - {})\".format(bins3_labels[0],bins3_labels[1],\n",
    "                                                                 bins3_labels[1],bins3_labels[2],\n",
    "                                                                 bins3_labels[2],bins3_labels[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Evaluate with 4 bins\n",
    "Y_bins4, bins4_labels, cv_res4, g4 = classifier_eval(classifiers,bins=4)\n",
    "g4.set_title(\"Cross Validation Score (4 Bins)\")\n",
    "plt.axvline(np.divide(1,4), color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Markup Percentage Bins:\\n [{} - {}), \\n [{} - {}), \\n [{} - {}), \\n [{} - {}]\".format(bins4_labels[0],bins4_labels[1],\n",
    "                                                                 bins4_labels[1],bins4_labels[2],\n",
    "                                                                 bins4_labels[2],bins4_labels[3],\n",
    "                                                                 bins4_labels[3],bins4_labels[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "g1=plot_learning_curve(lgr, 'Logistic Regression', X, Y_bins3, ylim=None, cv=cv,\n",
    "                       n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5))\n",
    "\n",
    "g2=plot_learning_curve(rfc, 'Random Forest', X, Y_bins3, ylim=None, cv=cv,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5))\n",
    "\n",
    "g3=plot_learning_curve(gbc, 'Gradient Boosting', X, Y_bins3, ylim=None, cv=cv,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5))\n",
    "\n",
    "g4=plot_learning_curve(abc, 'Ada Boosting', X, Y_bins3, ylim=None, cv=cv,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Tree Classifiers Feature Importance (With Three Bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit each classifier\n",
    "for classifier in classifiers[1:]:\n",
    "    classifier.fit(X,Y_bins3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 3\n",
    "ncols = 1\n",
    "fig, axes = plt.subplots(nrows = nrows, ncols = ncols, sharex=\"all\", figsize=(20,40),squeeze=False)\n",
    "\n",
    "names_classifiers = [(\"Random Forest\", rfc),(\"Gradient Boosting\",gbc),(\"Ada Boosting\",abc)]\n",
    "\n",
    "nclassifier = 0\n",
    "for row in range(nrows):\n",
    "    for col in range(ncols):\n",
    "        name = names_classifiers[nclassifier][0]\n",
    "        classifier = names_classifiers[nclassifier][1]\n",
    "        indices = np.argsort(classifier.feature_importances_)[::-1][:20]\n",
    "        g = sns.barplot(y=X.columns[indices][:20],x = classifier.feature_importances_[indices][:20] , orient='h',ax=axes[row][col])\n",
    "        g.set_xlabel(\"Relative importance\",fontsize=12)\n",
    "        g.set_ylabel(\"Features\",fontsize=12)\n",
    "        g.tick_params(labelsize=12)\n",
    "        g.set_title(name + \" feature importance\")\n",
    "        nclassifier += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis:\n",
    "Feature importance varies by classifier. However, the top seven features of each classifier (In varying orders) are TM min, Days on Sale, Spotify Average Followers, Average Ticket Listings, Days until Show, and Presale Length\n",
    "\n",
    "## 3.5 Hyperparameter Tuning\n",
    "I tune the hyperparameters of Logistic Regression, Random Forest, and Gradient Boosting classifiers using the training data (Target data is in 3 bins). Then, I combine the the three optimized models into a voting classifier and compare the results on the test data that was set aside earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Y test data into the same three bins\n",
    "Y_test3bins = pd.cut(x=Y_test,bins=bins3_labels,right=True,labels=[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Logistic Regression GridSearchCV\n",
    "lgr_params = {'C' : np.logspace(-3,1,10)}\n",
    "lgr_gs = GridSearchCV(lgr,param_grid=lgr_params,cv=cv,verbose=1,scoring='accuracy')\n",
    "\n",
    "#Setup Random Forest GridSearchCV\n",
    "rfc_params = {'criterion': ['gini','entropy'],\n",
    "              'max_features': ['auto','sqrt','log2'],\n",
    "              'min_samples_split': [.001,.005,.01]}\n",
    "rfc_gs = GridSearchCV(rfc,param_grid=rfc_params,cv=cv,verbose=1,scoring='accuracy')\n",
    "\n",
    "#Setup Gradient Boosting GridSearchCV\n",
    "gbc_params = {'n_estimators' : [100,200,300],\n",
    "              'max_depth': np.logspace(0,1,5),\n",
    "              'max_features' : ['auto','sqrt','log2']}\n",
    "gbc_gs = GridSearchCV(gbc,param_grid=gbc_params,cv=cv,verbose=1,scoring='accuracy')\n",
    "\n",
    "#Tune each GridSearchCV object\n",
    "gs_list = [lgr_gs,rfc_gs,gbc_gs]\n",
    "best_score = []\n",
    "for gs in gs_list:\n",
    "    gs.fit(X,Y_bins3)\n",
    "    best_score.append(gs.score(X_test,Y_test3bins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Model Ensembling and Comparison on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of clfs with best parameters and their labels\n",
    "best_clf = []\n",
    "for gs in gs_list:\n",
    "    best_clf.append(gs.best_estimator_)\n",
    "estimators = list(zip(['Logistic Regression','Random Forest','Gradient Boosting'],best_clf))\n",
    "\n",
    "#Initialize Voting Classifier\n",
    "votingClf = ensemble.VotingClassifier(estimators=estimators,voting='soft')\n",
    "votingClf.fit(X=X,y=Y_bins3)\n",
    "best_score.append(votingClf.score(X=X,y=Y_test3bins))\n",
    "\n",
    "#Wrap results into a dataframe    \n",
    "clf_test_results = pd.DataFrame({'Classifier' : ['Logistic Regression','Random Forest','Gradient Boosting','Combined'],\n",
    "                                'Best Score' : best_score})\n",
    "#Plot results\n",
    "sns.barplot(x='Best Score',y='Classifier',data=clf_test_results)\n",
    "plt.axvline(np.divide(1,3), color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Neural Net with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_y = np_utils.to_categorical(Y_bins3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_base_model():# Model \n",
    "    model = Sequential()\n",
    "    #input layer\n",
    "    model.add(Dense(units=74,input_dim=74,activation='relu',))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    #hidden layers\n",
    "    model.add(Dense(38,activation='sigmoid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model compile for classification\n",
    "#estimator = build_base_model()\n",
    "#model.fit(X, dummy_y, epochs=100, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "estimator = KerasClassifier(build_fn=build_base_model,epochs=100, batch_size=30)\n",
    "score = cross_val_score(estimator,X=X,y=Y_bins3,cv=kfold,scoring='accuracy',verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
