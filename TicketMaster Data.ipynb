{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import datetime\n",
    "import requests\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of cities and Ticketmaster codes\n",
    "City_List = \n",
    "    'Denver' : 264,\n",
    "    'San Francisco Bay': 382,\n",
    "    'Portland': 362,\n",
    "    'Los Angeles': 27,\n",
    "    'Las Vegas' : 14,\n",
    "    'Phoenix': 36, \n",
    "    'Seattle': 42,\n",
    "    'Austin' : 40, \n",
    "    'Houston': 22,\n",
    "    'Dallas' : 5,\n",
    "    'Chicago': 3,\n",
    "    'Nashville': 31,\n",
    "    'Atlanta': 10,\n",
    "    'Boston' : 11,\n",
    "    'New York': 35,\n",
    "    'Washington DC': 47,\n",
    "    'Miami' : 15\n",
    "### Ticketmaster API info    \n",
    "base_url = 'https://app.ticketmaster.com/discovery/v2/events.json?countryCode=US&apikey={apikey}'\n",
    "api_key = 'OhKdHqBZOOuGCrWIcjlhzoxmnjUoaGWL'\n",
    "dmaId = [382,362,264]\n",
    "marketId =  [42,27,14,36,40,22,5,3,31,10,11,35,47,15]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions\n",
    "\n",
    "Define functions for pulling event data from Ticketmaster API and formatting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#DMA and Market numbers\n",
    "dma_list = [382,362,264]\n",
    "mkt_list =  [42,27,14,36,40,22,5,3,31,10,11,35,47,15]\n",
    "\n",
    "# Function to get the number of pages of ticketmaster data\n",
    "def get_number_of_TM_pages(dma=None,market=None,source='ticketmaster,frontgate'):\n",
    "    url = 'https://app.ticketmaster.com/discovery/v2/events.json?countryCode=US'\n",
    "    payload = {'dmaId': dma, \n",
    "               'marketId': market, \n",
    "               'source': source,\n",
    "               'classificationName': 'music',\n",
    "               'size': '200',\n",
    "               'apikey':'OhKdHqBZOOuGCrWIcjlhzoxmnjUoaGWL'}\n",
    "    r = requests.get(url,params=payload,verify=True)\n",
    "    json_obj = json.loads(r.text)\n",
    "    return json_obj['page']['totalPages']\n",
    "\n",
    "#Get TicketMaster data, return a dataframe\n",
    "def getTicketMasterData(dma=None,market=None,page=None, source='ticketmaster,frontgate'):\n",
    "    url = 'https://app.ticketmaster.com/discovery/v2/events.json?countryCode=US'\n",
    "    payload = {'dmaId': dma, \n",
    "               'marketId': market, \n",
    "               'source': source,\n",
    "               'classificationName' : 'music',\n",
    "               'sort': 'date,name,asc',\n",
    "               'size': '200',\n",
    "               'page': page,\n",
    "               'apikey':'OhKdHqBZOOuGCrWIcjlhzoxmnjUoaGWL'}\n",
    "    r = requests.get(url,params=payload,verify=True)\n",
    "    json_response = json.loads(r.text)\n",
    "    event_info = []\n",
    "    for event in json_response.get('_embedded',{}).get('events',{}):\n",
    "         event_info.append({\n",
    "            'TM_id': event.get('id',{}),\n",
    "            'TM_name' : event.get('name',{}),\n",
    "            'TM_artist': list(attraction.get('name') for attraction in event['_embedded'].get('attractions',{})),\n",
    "            'TM_venue' : list(venue.get('name') for venue in event['_embedded'].get('venues',{}))[0],\n",
    "            'TM_venue_city' : list(venue.get('city',{}).get('name') for venue in event['_embedded'].get('venues',{}))[0],\n",
    "            'TM_venue_state' : list(venue.get('state',{}).get('stateCode') for venue in event['_embedded'].get('venues',{}))[0],\n",
    "            'TM_description' : event.get('description',{}),\n",
    "            'TM_more_info' : event.get('additionalInfo',{}),\n",
    "            'TM_start_date' : event.get('dates',{}).get('start',{}).get('dateTime',{}),\n",
    "            'TM_timezone' : event.get('dates',{}).get('timezone'),\n",
    "            'TM_span_multiple_days' : event.get('dates',{}).get('spanMultipleDays'),\n",
    "            'TM_presale_date_start' : list(presale.get('startDateTime',{}) for presale in event.get('sales').get('presales',{})),\n",
    "            'TM_presale_date_end' : list(presale.get('endDateTime',{}) for presale in event.get('sales').get('presales',{})),\n",
    "            'TM_sale_date_start' : event.get('sales',{}).get('public',{}).get('startDateTime'),\n",
    "            'TM_FV_prices': event.get('priceRanges'),\n",
    "            'TM_promoter': event.get('promoter',{}).get('name'),\n",
    "            'TM_genre' : event.get('classifications'),\n",
    "            'TM_place' : event.get('place')\n",
    "         })\n",
    "    tmDF = pd.DataFrame(event_info)\n",
    "    return tmDF\n",
    "\n",
    "#Convert timedate information from UTC to local time\n",
    "def convert_times(df,times_list,tz_col):\n",
    "    #Loop through each timezone\n",
    "    df_list = []\n",
    "    for tz in df[tz_col].unique():\n",
    "        #Filter rows by timezone\n",
    "        mask = (df[tz_col] == tz)\n",
    "        df_local = df.loc[mask]\n",
    "        #Loop through each datetime row\n",
    "        for col in times_list:\n",
    "            #Convert each column to datetime series, localize to UTC and then convert to proper timezone\n",
    "            df_local[col] = pd.to_datetime(df_local[col],errors='coerce').dt.tz_localize('UTC').dt.tz_convert(tz)\n",
    "            #Convert each column to datetime series, localize to UTC and then convert to proper timezone\n",
    "        df_list.append(df_local)\n",
    "    df = pd.concat(df_list, axis=0)\n",
    "    return df\n",
    "\n",
    "#Explode out columns with nested information\n",
    "def explode(df,col,index):\n",
    "    df1 = df[col].apply(pd.Series)\n",
    "    df1.index = df[index]\n",
    "    df1 = df1[0].apply(pd.Series)\n",
    "    df = df.join(df1, on=index)\n",
    "    df = df.drop(col,axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Ticketmaster face value data\n",
    "### Pull the data and create the data frame\n",
    "For each city/market, get the number of pages of data, pull all data, and then concatanate the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv_df_list = []\n",
    "\n",
    "#Create dictionaries of dma/mkt numbers, and number of pages of data\n",
    "dma_dict = dict()\n",
    "mkt_dict = dict()\n",
    "#Get number of pages for face value dma items\n",
    "for dma in dma_list:\n",
    "    dma_dict[dma] = get_number_of_TM_pages(dma=dma)\n",
    "    \n",
    "#Get DMA data\n",
    "for dma in dma_dict.keys():\n",
    "    for page in range(1,dma_dict[dma]+1):\n",
    "        fv_df_list.append(getTicketMasterData(dma=dma,page=page))\n",
    "    \n",
    "#Get number of pages for face value market items\n",
    "for mkt in mkt_list:\n",
    "    mkt_dict[mkt] = get_number_of_TM_pages(market=mkt)\n",
    "    \n",
    "#Get market data\n",
    "for mkt in mkt_dict.keys():\n",
    "    for page in range(1,mkt_dict[mkt]+1):\n",
    "        fv_df_list.append(getTicketMasterData(market=mkt,page=page))\n",
    "        \n",
    "#Combine all dataframes for full data on events and face_value prices\n",
    "fv_df = pd.concat(fv_df_list,axis=0)\n",
    "\n",
    "fv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert datetime columns to datetime objects in  proper timezones\n",
    "Currently the four columns with datetime information are a mess. Some are of type dict, some are nested in lists, and all are in the UTC timezone. We can look and see that in timedate columns with lists of dates, the timedates are identitical, so we can unnest datetimes by simply taking the first element of the list.\n",
    "\n",
    "The 3 things we need to accomplish:\n",
    "    1. Convert all datetime columns to dtype string, and unnest 'TM_presale_date_end' and 'TM_presale_date_start' columns\n",
    "    2. Convert all columns to datetime series localized to UTC (Done in the convert_times function)\n",
    "    3. Filter rows by timezone, and loop over each datetime column to convert objects to their proper timezone (Done in the convert_times function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert all datetime columns to dtype string, and unnest objects\n",
    "fv_df['TM_presale_date_end'] = fv_df['TM_presale_date_end'].str[0]\n",
    "fv_df['TM_presale_date_start'] = fv_df['TM_presale_date_start'].str[0]\n",
    "fv_df['TM_start_date'] = fv_df['TM_start_date'].astype(str)\n",
    "fv_df['TM_sale_date_start'] = fv_df['TM_sale_date_start'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. Convert all columns to datetime series localized to UTC\n",
    "# 3. Filter rows by timezone and create a new dataframe per timezone, loop over each datetime column to convert objects to their proper timezone \n",
    "col_list = ['TM_presale_date_end','TM_presale_date_start','TM_start_date','TM_sale_date_start']\n",
    "fv_df = convert_times(df=fv_df,times_list=col_list,tz_col='TM_timezone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explode nested rows\n",
    "Unnest information in prices and genre column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Explode price dictionaries\n",
    "fv_df = explode(fv_df,'TM_FV_prices','TM_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Unnest genre info and clean up data in exploded columns\n",
    "fv_df = explode(fv_df,'TM_genre','TM_id')\n",
    "for col in ['segment','subGenre','subType','type']:\n",
    "    fv_df.col = fv_df.col.map(lambda x: x.get('name',{}))\n",
    "fv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query TicketMaster resale data and merge with face value data\n",
    "Next we will query TicketMaster's resale ticket data and then merge it with the face value dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query resale data from the Ticketmaster API\n",
    "\n",
    "rv_df_list = []\n",
    "\n",
    "#Create dictionaries of dma/mkt numbers, and number of pages of data\n",
    "dma_rv_dict = dict()\n",
    "mkt_rv_dict = dict()\n",
    "#Get number of pages for resale value dma items\n",
    "for dma in dma_list:\n",
    "    dma_rv_dict[dma] = get_number_of_TM_pages(dma=dma,source='tmr')\n",
    "    \n",
    "#Get DMA data\n",
    "for dma in dma_rv_dict.keys():\n",
    "    for page in range(1,dma_dict[dma]+1):\n",
    "        fv_df_list.append(getTicketMasterData(dma=dma,page=page,source='tmr'))\n",
    "    \n",
    "#Get number of pages for resale value market items\n",
    "for mkt in mkt_list:\n",
    "    mkt_rv_dict[mkt] = get_number_of_TM_pages(market=mkt,source='tmr')\n",
    "    \n",
    "#Get market data\n",
    "for mkt in mkt_rv_dict.keys():\n",
    "    for page in range(1,mkt_dict[mkt]+1):\n",
    "        fv_df_list.append(getTicketMasterData(market=mkt,page=page,source='tmr'))\n",
    "        \n",
    "#Combine all dataframes for full data on events and resale value prices\n",
    "rv_df = pd.concat(fv_df_list,axis=0)\n",
    "rv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract price information and merge it with face value data in a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode out reslaeprice information\n",
    "rv_df = explode(rv_df,'TM_FV_prices','TM_id')\n",
    "rv_df.rename(columns={'min': 'tmr_min', 'max': 'tmr_max'}, inplace=True)\n",
    "# Create a new dataframe combining face value and resale value information, joined on ticketmaster event ID\n",
    "joined_df = fv_df.join(rv_df[['tmr_min','tmr_max']],on='TM_id',how='outer')\n",
    "joined_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
